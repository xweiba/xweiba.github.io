{"title":"Js-Web转PDf框架的设计与实现","uid":"16e3b72ab86bdd03c61cdf559c2dc7de","slug":"Js-Web转PDf框架的设计与实现","date":"2025-04-29T09:38:40.000Z","updated":"2025-04-30T08:11:18.860Z","comments":true,"path":"api/articles/Js-Web转PDf框架的设计与实现.json","keywords":null,"cover":null,"content":"<ul>\n<li>设计开发了一个输出标准A3、A4等指定大小的PDF前端js框架，支持实时预览和字符级自适应分页，实时获取业务dom的精准坐标信息，所见即所得。后端使用Egg.js和Puppetteer构建Web转PDF文件服务，提供单机平均 200笔&#x2F;m PDF导出的稳定服务。完成Web端试卷、答题卡、批阅卡等业务的实时编辑、预览、排版与PDF导出，上线一个月稳定后成为标准的Web转PDF生成基础设施供其他开发组使用。</li>\n</ul>\n<p>前端使用Js实现一个框架，<br>使用css ‘page-break-after: always;’ 实现换页。<br>第一版：转为答题卡设计，一个a4大小的模板dom，然后通过js将固定的dom插入到指定位置，然后通过css ‘page-break-after: always;’ 实现换页。后端使用 <code>java-wkhtmltopdf-wrapper</code> 调用wkhtmltopdf命令行工具生成PDF文件, 我给他提交过pr。<br>第一版在答题卡场景下是够用的，所有dom都是固定的。<br>第二版: 由于业务需要，我们需要将线上试卷打印出来给线下答题，而题目大多数都是第三方导入的，dom结构是不确定的，并且要支持将dom拆分，一个题目内容像文章一样自动切分，经过我的调研，wk是不行的，因为它的wekit内核太老了，不支持es6语法，部分题目的样式它不支持，js直接生成pdf文件都是直接截图的，太大了，我们后期可能要将整本书都弄进来，位置也会产生变化，而且我们需要在后端生成pdf，最终确定使用Puppetteer调用chrome的打印功能来做。</p>\n<p>前端在原来的基础上，我们做了一个自适应分页的框架，设计理念就是页面所有内容都是一个block块，包含PageBlock, loyoutBlock, ContentBlock，三个类型，PageBlock和LayoutBlock生成通过配置文件定义，由框架自动生成，ContentBlock 由数据适配器根据业务数据生成, 每页初始化时，框架会先根据配置生成对应的PageBlock和LayoutBlock，然后将ContentBlock依次渲染到当前渲染中的容器中，block放不下就触发溢出处理，dom是没法通过文字计算高度的，通过二分法，将内容拆一半，然后再判断是否能放下，放不下就继续二分，直到能放下为止，然后再将剩余的内容生成新的block，后面按这样的将所有block生成完，我们可以轻松通过配置文件定义PDF页面的整体布局，比如竖版和横板。</p>\n<ul>\n<li>数据适配器 将业务数据转为框架需要的渲染的元数据，包含page,layout,block</li>\n<li>渲染处理器 将元数据渲染到容器中</li>\n<li>数据构建器 构建框架，将数据适配器和渲染处理器组合起来，生成一个完整的框架</li>\n<li>block基类 工厂方法，生成block</li>\n<li>PageBlock基类 定义页大小<br>这里面的坑，第一个图片，图片必须等待它完全加载后才能执行下一个，字体，必须使用自定义字体，否则linux和windows渲染可能有偏移导致不一致。</li>\n</ul>\n<p>后端 Puppetteer 官方支持nodejs, 我使用了egg.js创建了一个web服务，然后通过generic-pool创建了一个线程池，通过配置文件控制线程池中chrome的总实例和page的总实例。对外暴露一个接口来调用pdf生成，要生成的url经过base64转换，防止参数丢失。</p>\n<p>最大的坑，字体，Linux端和windows端字体渲染高度不一致，导致两边pdf不一样，自定字体解决，<br>chrome内核版本，不同chrome内核渲染结果不一样，特别是老版本的，需要定期更新。<br>由于框架内容是异步生成的，必须在页面设置钩子，来确保内容生成完毕后在生成pdf。</p>\n<ul>\n<li><p>使用Tensoflow训练手写分类模型，基于MNIST手写数据集训练英文与数字字符模型，收集自定义数据集完成批阅勾、叉、划线等字符的自定义分类模型，并设计数据收集方案，定期进行增量训练，性优化网络结构，提升识别能力，识别率从刚上线的85%到97%+。模型通过TF Java后端接入系统，并部署到小程序，平板端完成部分离线识别场景. cnn 卷积神经网络，图片转为单通道，归一化， 3*3 取 28 个特征，池化，全连接，要定义模型的输入名称，输出名称，不然java的后端模型载入时必须传入正确的名称否则无法初始化。<br>难点：找数据，github上有一个手写数字和英文字符的数据集 extra_keras_datasets，我提交过pr，<br>数据标注：我们的流程是批阅完成后，老师需要手动检查结果，有问题的需要老师手动修改，我们会对这个数据进行标注。然后每个月专们去看下标注结果，然后每个星期一，去看看这个识别错误的数据，重新标注，有定时任务在月底自动做增量训练。数据量不够，模型训练效果不够好，必须累积一下。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def model_build(self):</span><br><span class=\"line\">    # 构建模型</span><br><span class=\"line\">    model = Sequential([</span><br><span class=\"line\">        # 接收单通道图</span><br><span class=\"line\">        Input([28, 28, 1], name=&#x27;init_operation&#x27;),</span><br><span class=\"line\">        # 归一化</span><br><span class=\"line\">        Rescaling(1. / 255),</span><br><span class=\"line\">        # 卷积核 大小(3*3) 提取28个特征,</span><br><span class=\"line\">        # 默认使用&quot;same&quot;填充方式，确保输出特征图的大小与输入特征图一致。</span><br><span class=\"line\">        # 输入形状为28x28的灰度图像。激活函数为ReLU。</span><br><span class=\"line\">        Conv2D(28, 3, activation=&#x27;relu&#x27;),</span><br><span class=\"line\">        # 添加了一个最大池化层，将图像的尺寸缩小一半。</span><br><span class=\"line\">        # 对输入特征图进行空间降维。通过将2x2的池化窗口应用于输入特征图，每个窗口中的最大值被选择作为输出特征图的单个像素。</span><br><span class=\"line\">        # 这样可以减小特征图的空间尺寸，从而提取出更具有代表性的特征。</span><br><span class=\"line\">        MaxPooling2D((2, 2)),</span><br><span class=\"line\">        #  降维后特征会比较明显，所以提取的特征点会增大</span><br><span class=\"line\">        Conv2D(64, (3, 3), padding=&#x27;same&#x27;, activation=&#x27;relu&#x27;),</span><br><span class=\"line\">        # 第一个MaxPooling2D操作将特征图的尺寸从28x28缩小到14x14，第二次MaxPooling2D操作将特征图的尺寸进一步缩小到7x7。</span><br><span class=\"line\">        # 通过这种逐步减小特征图尺寸的方式，可以提取出更抽象、更高级的特征，使得模型更具有表征能力。</span><br><span class=\"line\">        MaxPooling2D((2, 2)),</span><br><span class=\"line\">        # 将输入的多维特征图转换为一维向量，以便将其作为输入传递给后续的全连接层</span><br><span class=\"line\">        Flatten(),</span><br><span class=\"line\"></span><br><span class=\"line\">        # 全连接，一个具有512个神经元和ReLU激活函数的全连接层。</span><br><span class=\"line\">        # 全连接层的目的是将前一层的特征转换为当前层的特征，并通过学习连接权重和非线性变换，实现模型的分类或回归任务。</span><br><span class=\"line\"></span><br><span class=\"line\">        # 通过连接前一层的所有神经元和当前层的所有神经元，将前一层的特征映射转换为当前层的特征映射。</span><br><span class=\"line\">        # 每个神经元在全连接层中都与前一层的所有神经元相连接，这样可以保留并整合前一层的所有信息。</span><br><span class=\"line\">        # 它通常是神经网络模型的最后一层，用于将前面的特征提取层（如卷积层或池化层）学到的特征进行分类或回归。</span><br><span class=\"line\">        # 通过全连接层，模型可以将高级抽象的特征转换为最终的输出结果。</span><br><span class=\"line\">        # 在全连接层中，神经元之间的连接权重可以通过反向传播算法进行学习和优化，以达到更准确的模型输出。</span><br><span class=\"line\">        # 通常，在全连接层之后会使用激活函数对每个神经元的输出进行非线性变换，进一步增强模型的表达能力。</span><br><span class=\"line\">        Dense(512, activation=&#x27;relu&#x27;),</span><br><span class=\"line\">        # 在训练过程中随机丢弃10%的神经元，以防止过拟合</span><br><span class=\"line\">        Dropout(0.1),</span><br><span class=\"line\">        Dense(128, activation=&#x27;relu&#x27;),</span><br><span class=\"line\">        Dropout(0.1),</span><br><span class=\"line\">        # 输出层的单元数量，对应分类任务分类数</span><br><span class=\"line\">        Dense(self.target_labels_len, activation=&#x27;softmax&#x27;, name=&#x27;end_operation&#x27;)</span><br><span class=\"line\">    ])</span><br><span class=\"line\">    return model</span><br></pre></td></tr></table></figure></li>\n<li><p>交卷智能识别处理，通过PDF生成框架完成PDF文件与坐标数据的生成。打印后学生纸笔答题，通过拍照或扫描仪提交答卷图片，后端使用OpenCV通过锚点定位和透视变换等处理，通过坐标信息，识别选择题答案，非选择题截取后录入系统。</p>\n</li>\n<li><p>智能纸笔批阅系统，依托PDF生成框架生成标准的A3、A4试卷、批阅卡，答题卡等业务的详细坐标信息，配合第三方PDF点阵铺码完成试卷、答题卡、批阅卡等物料的制作， 用户通过点阵笔上传批阅和答题等手写数据，使用识别模型完成自动化批阅，打通线下纸笔与线上数据难以互通的问题，补全数字化课堂最重要的一个业务场景。</p>\n</li>\n<li><p>缓存工具设计，通过Caffeine本地与Redis实现双缓存机制，有效减少redis缓存延时带来的性能问题。只在热点接口上使用内存缓存。</p>\n</li>\n<li><p>动态定时任务下发，通过api可动态创建在指定时间执行某个服务的的某个接口，完成预热等服务的实现，提前将热点数据缓存。解决期中、期末大型线上考试等热点接口的迅时流量问题。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">通过定时任务在每天凌晨查询预热表中今天要考试的测验，将这些测验根据时间都加到缓存预热队列中。在测验修改和新增的接口使用aop，将他们加到缓存预热队列中，</span><br><span class=\"line\">缓存预热队列有一个定时任务，每十分钟执行一次，查看这十分钟内是否有要考试的测验，有就执行对应的handel去解析需对应的任务数据，通过getBean获取实例，通过反射执行对应的方法。</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缓存系统数据不一致优化，原缓存系统存在Redis与Mysql数据不一致问题，如测验、资源包等关键业务更新时时常出现不一致问题，通过引入Canal对关键业务表监控，基本解决Redis与Mysql数据不一致性问题。</p>\n</li>\n</ul>\n<ol>\n<li>其他组部署的Canal服务，通过订阅Mysql的binlog日志，将变更的数据同步到Redis。</li>\n<li>编写试卷表的监听器，继承EntryHandler接口，实现数据变更时的回调，将变更的数据同步到Redis。</li>\n</ol>\n<ul>\n<li><p>第三方服务对接，部分资源需要接入第三方服务，根据整体架构及商务需求，开发对接系统，所有第三方服务都通过云端对接其SDK，由客户端发起调用，云端作为代理，支持实时和异步处理，异步处理提供回调接口，实现华翰云网阅系统、学科网、极值网等各种第三方教学服务接入。</p>\n</li>\n<li><p>内容爬取器，将第三方数据持久化并将其中的网络资源扫描并上传至本地文件服务。<br>简单的直接逆袭接口，实现前面或登录。<br>复杂一点无法逆向的，编写一个chrome插件，实现自动登录，然后开始爬数据，都不用加密解密接口，只要web能看到，就可以爬。</p>\n</li>\n<li><p>通过第三方OCR接口将资源组截图录入资源识别并录入ES。</p>\n</li>\n<li><p>源码中文翻译处理器：台湾项目不允许出现简体字，配合翻译API将源码中所有的中文注释都翻译<br>为繁体。<br>判断字符是否在[\\u4e00-\\u9fa5]这个范围内，如果是，则认为是中文。使用解释器模式，将源码中的中文注释提取出来，然后调用翻译API，将中文注释翻译为繁体。</p>\n</li>\n<li><p>年会抽奖系统设计，通过Redis中Set的随机接口为核心，设计了一个抽奖系统。<br>非常简单，通过Redis的Set数据结构，将所有的用户ID存入Redis中，然后通过Redis的随机接口 SPOP key [count] ，随机取出一个用户ID，即为中奖用户，安慰奖几个，三等奖几个，已中奖的用户不再参与后面的抽奖。</p>\n<ul>\n<li>Redis基础数据结构，String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）</li>\n</ul>\n</li>\n<li><p>协助文件服务组接入阿里云OSS，解决云端文件下载带宽不足问题。</p>\n</li>\n<li><p>开发支持Android端的业务处理Java Lib包。</p>\n</li>\n<li><p>推动Vue开发部分业务及前后端分离架构，Angular重构前端业务。</p>\n</li>\n<li><p>各种服务、依赖部署文档的编写及其它业务需求开发。</p>\n</li>\n</ul>\n","text":" 设计开发了一个输出标准A3、A4等指定大小的PDF前端js框架，支持实时预览和字符级自适应分页，实时获取业务dom的精准坐标信息，所见即所得。后端使用Egg....","permalink":"/post/Js-Web转PDf框架的设计与实现","photos":[],"count_time":{"symbolsCount":"5.2k","symbolsTime":"5 mins."},"categories":[],"tags":[{"name":"Js，NodeJs,PDF,Js框架","slug":"Js，NodeJs-PDF-Js框架","count":1,"path":"api/tags/Js，NodeJs-PDF-Js框架.json"}],"toc":"","author":{"name":"Weiba","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/24520686?v=4","link":"/","description":"啊 又忘了更新了！","socials":{"github":"https://github.com/xweiba","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"设计模式-概述","uid":"2a65e05f182b95ab6109ed82fd948943","slug":"设计模式-概述","date":"2025-04-29T13:35:19.000Z","updated":"2025-04-30T08:11:18.902Z","comments":true,"path":"api/articles/设计模式-概述.json","keywords":null,"cover":null,"text":" DesignPattern 观察者模式主题 Subject 维护订阅者 内部维护一个订阅者列表 List<Observer> observers regist...","permalink":"/post/设计模式-概述","photos":[],"count_time":{"symbolsCount":"3.8k","symbolsTime":"3 mins."},"categories":[{"name":"编程","slug":"编程","count":8,"path":"api/categories/编程.json"},{"name":"设计模式","slug":"编程/设计模式","count":8,"path":"api/categories/编程/设计模式.json"}],"tags":[{"name":"设计模式","slug":"设计模式","count":8,"path":"api/tags/设计模式.json"},{"name":"软件架构","slug":"软件架构","count":1,"path":"api/tags/软件架构.json"}],"author":{"name":"Weiba","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/24520686?v=4","link":"/","description":"啊 又忘了更新了！","socials":{"github":"https://github.com/xweiba","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Java-基于Redis的高性能任务队列设计与实现","uid":"6456b03f672a87198a79af9e60f25dff","slug":"Java-基于Redis的高性能任务队列设计与实现","date":"2025-04-29T09:19:39.000Z","updated":"2025-04-30T08:11:18.852Z","comments":true,"path":"api/articles/Java-基于Redis的高性能任务队列设计与实现.json","keywords":null,"cover":null,"text":"我们早期2.0系统交卷是同步提交，交一笔写一笔，还要做各种逻辑处理，通知其他服务修改活动状态，在班级考试里还能用，只是慢，qps不超50, 后来需要支持年级考试...","permalink":"/post/Java-基于Redis的高性能任务队列设计与实现","photos":[],"count_time":{"symbolsCount":"3.1k","symbolsTime":"3 mins."},"categories":[],"tags":[{"name":"Java","slug":"Java","count":11,"path":"api/tags/Java.json"},{"name":"请求合并","slug":"请求合并","count":1,"path":"api/tags/请求合并.json"},{"name":"Redis阻塞队列","slug":"Redis阻塞队列","count":1,"path":"api/tags/Redis阻塞队列.json"},{"name":"任务队列","slug":"任务队列","count":1,"path":"api/tags/任务队列.json"}],"author":{"name":"Weiba","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/24520686?v=4","link":"/","description":"啊 又忘了更新了！","socials":{"github":"https://github.com/xweiba","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}